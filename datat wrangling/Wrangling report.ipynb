{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Project description: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this project of data wrangling we have started from a messy data and end up concluding the analysis.\n",
    "Process involve in this project are:\n",
    "1) Cleaning of dataset which involve first twitter data that contains information about twitter users second twitter Api third Algorithm implemented on dog’s data's result.\n",
    "\n",
    "2) After cleaning we analyses the data set and combined it.\n",
    "\n",
    "Data is successfully gathered:\n",
    "\n",
    "From at least the three (3) different sources on the Project Details page.\n",
    "In at least the three (3) different file formats on the Project Details page.\n",
    "Each piece of data is imported into a separate pandas DataFrame at first.\n",
    "\n",
    "\n",
    "Two types of assessment are used:\n",
    "\n",
    "Visual assessment: each piece of gathered data is displayed in the Jupyter Notebook for visual assessment purposes. Once displayed, data can additionally be assessed in an external application (e.g. Excel, text editor).\n",
    "Programmatic assessment: pandas' functions and/or methods are used to assess the data.\n",
    "\n",
    "Rating numerators have not been properly cleaned. The current pipeline captures incorrect values when rating numerators contain decimals.\n",
    "\n",
    "Currently, the value 75 would be captured as the rating numerator. Try to capture the entire value from the text instead. \n",
    "ratings series object will then contain all rating numerators with decimals and rating denominators (without decimals). The next step is to extract only the numerators and denumerators from ratings dataframe, and then update your dataset's fields with extracted rating numerators and denominators\n",
    "\n",
    "Also, this issue correction needs to be updated:\n",
    "\n",
    "Merge multiple dog stages\n",
    "\n",
    "There are cases where there are multiple dog stages in a row. Here is how to find them (df here is the Twitter archive dataset).\n",
    "\n",
    "The pipeline needs to handle these cases. One way to do so is by concatenating them with commas (\",\") .\n",
    "\n",
    "3) After analysing we concluded our finding via graphs.\n",
    "\n",
    "Key Points\n",
    "Key points to keep in mind when data wrangling for this project:\n",
    "\n",
    "•\tYou only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings, and some are retweets.\n",
    "\n",
    "•\tAssessing and cleaning the entire dataset completely would require a lot of time and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "\n",
    "•\tCleaning includes merging individual pieces of data according to the rules of tidy data.\n",
    "\n",
    "•\tThe fact that the rating numerators are greater than the denominators does not need to be cleaned. This unique rating system is a big part of the popularity of WeRateDogs.\n",
    "\n",
    "•\tYou do not need to gather the tweets beyond August 1st, 2017. You can but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Cleaning Data: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* drop 'in_reply_to_status_id', 'in_reply_to_user_id, 'expanded_urls'\n",
    "* change the timestamp data type\n",
    "* change the tweet_id data type of all the dataset \n",
    "* changing the rating data types \n",
    "* Ratings are very inaccurate\n",
    "* choose the tweet which is not retweet\n",
    "* replace invalid names with None\n",
    "* Keeping rows with p1_dog, p2_dog, or p3_dog = True. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tidy master dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tidy the 4 stages of dog column to create variable\n",
    "* Concatenate all datasets to make one clean dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
